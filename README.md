# ğŸ“Š Machine Learning Pipeline with Python & PySpark


[![Python](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/)
[![PySpark](https://img.shields.io/badge/pyspark-3.5.1-orange.svg)](https://spark.apache.org/docs/latest/api/python/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](#)

---

## ğŸ“– Overview

This project is a **Machine Learning Data Pipeline** built using Python, PySpark, Docker, and PostgreSQL.  
It follows a modular ETL (Extract, Transform, Load) and Machine Learning workflow that simulates real-world data processing scenarios.

The pipeline extracts data from Google Spreadsheets, stages it in a PostgreSQL database, transforms it, and loads it into a data warehouse. Finally, a machine learning model is trained, evaluated, and logged.

---

## ğŸ“¦ Pipeline Architecture

**Spreadsheet â†’ Staging DB (PostgreSQL) â†’ Warehouse DB (PostgreSQL) â†’ Machine Learning (PySpark + Sklearn)**  

### ğŸ“Œ ETL Pipeline:
- Extract data from spreadsheet  
- Load to **staging database**
- Data transformation
- Load to **warehouse database**

### ğŸ“Œ ML Pipeline:
- Extract data from **warehouse**
- Data preprocessing
- **Train-test split** ğŸ‘‰ performed **before outlier removal** to avoid *data leakage*
- Outlier removal only on **training set**
- Train a Decision Tree model
- Evaluate performance on the **original test set**

---

## ğŸ› ï¸ Tools & Libraries

- Python 3.11  
- PySpark 3.5.1  
- PostgreSQL (Dockerized)  
- Pandas, Numpy, Scikit-learn  
- dotenv  
- Logging  
- Docker & Docker Compose  

---

## Project Structure
```
machine_learning_pipeline/
â”œâ”€â”€ log/                         # Log file directory
â”‚   â””â”€â”€ info_process.log
â”œâ”€â”€ marketing_staging/           # Staging database init scripts
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ marketing_warehouse/         # Warehouse database init scripts
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ src/                         # Source code modules
â”‚   â”œâ”€â”€ staging/
â”‚   â”œâ”€â”€ warehouse/
â”‚   â”œâ”€â”€ modeling/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ .flake8                      # Flake8 linting config
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ docker-compose.yml           # Docker Compose config
â”œâ”€â”€ live_class_week_8.ipynb      # Jupyter notebook for live session
â”œâ”€â”€ pipeline.py                  # Main pipeline script
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ tempCodeRunnerFile.py        # Temp file (can be ignored)


```
